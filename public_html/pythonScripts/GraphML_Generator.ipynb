{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0973fb65-52f2-445d-87a4-b46b1206939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML written to output.xml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"./../draft_six_columns.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def create_xml_node(row):\n",
    "    data_piece_name = row['Target']\n",
    "    subcategory = row['Subcategory']\n",
    "    category = row['Category']\n",
    "    kind = row['Kind']\n",
    "    \n",
    "    xml_structure = f\"\"\"\n",
    "<node id=\"{data_piece_name}\">\n",
    "    <data key=\"level_0\">{data_piece_name}</data>\n",
    "    <data key=\"level_1\">{subcategory}</data>\n",
    "    <data key=\"level_2\">{category}</data>\n",
    "    <data key=\"level_3\">{kind}</data>\n",
    "    <data key=\"d0\">{data_piece_name}</data>\n",
    "    <data key=\"d1\">DATA</data>\n",
    "</node>\n",
    "\"\"\"\n",
    "    return xml_structure\n",
    "\n",
    "def create_actor_node(actor_name):\n",
    "    xml_structure = f\"\"\"\n",
    "<node id=\"{actor_name}\">\n",
    "    <data key=\"d0\">{actor_name}</data>\n",
    "    <data key=\"d1\">ACTOR</data>\n",
    "</node>\n",
    "\"\"\"\n",
    "    return xml_structure\n",
    "\n",
    "def create_subsum_edges(row, created_subsum_edges):\n",
    "    data_piece_name = row['Target']\n",
    "    subcategory = row['Subcategory']\n",
    "    category = row['Category']\n",
    "    kind = row['Kind']\n",
    "\n",
    "    edges = []\n",
    "    # Avoid repeating subsum edges by tracking created relationships\n",
    "    if (subcategory, data_piece_name) not in created_subsum_edges:\n",
    "        edges.append(f\"\"\"\n",
    "<edge source=\"{subcategory}\" target=\"{data_piece_name}\" id=\"edge_subsum_{subcategory}_{data_piece_name}\">\n",
    "    <data key=\"d2\">SUBSUM</data>\n",
    "</edge>\n",
    "\"\"\")\n",
    "        created_subsum_edges.add((subcategory, data_piece_name))\n",
    "\n",
    "    if (category, subcategory) not in created_subsum_edges:\n",
    "        edges.append(f\"\"\"\n",
    "<edge source=\"{category}\" target=\"{subcategory}\" id=\"edge_subsum_{category}_{subcategory}\">\n",
    "    <data key=\"d2\">SUBSUM</data>\n",
    "</edge>\n",
    "\"\"\")\n",
    "        created_subsum_edges.add((category, subcategory))\n",
    "\n",
    "    if (kind, category) not in created_subsum_edges:\n",
    "        edges.append(f\"\"\"\n",
    "<edge source=\"{kind}\" target=\"{category}\" id=\"edge_subsum_{kind}_{category}\">\n",
    "    <data key=\"d2\">SUBSUM</data>\n",
    "</edge>\n",
    "\"\"\")\n",
    "        created_subsum_edges.add((kind, category))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def create_collect_edges(row, collect_edges_tracker):\n",
    "    data_piece_name = row['Target']\n",
    "    actor = row['Source']\n",
    "    text = row['Text']\n",
    "\n",
    "    # Track collect edges by (actor, data_piece_name) pair\n",
    "    if (actor, data_piece_name) not in collect_edges_tracker:\n",
    "        collect_edges_tracker[(actor, data_piece_name)] = [text]\n",
    "    else:\n",
    "        collect_edges_tracker[(actor, data_piece_name)].append(text)\n",
    "\n",
    "def generate_xml_from_dataframe(df, output_file):\n",
    "    xml_actor_nodes = ''\n",
    "    xml_data_nodes = ''\n",
    "    xml_subsum_edges = ''\n",
    "    xml_collect_edges = ''\n",
    "    edge_id_counter = 0\n",
    "\n",
    "    actor_nodes = set()  # To track actor nodes\n",
    "    data_nodes = set()  # To track data nodes\n",
    "    created_subsum_edges = set()  # To track subsum relationships\n",
    "    collect_edges_tracker = {}  # To track collect relationships with multiple texts\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Add actor node if not already created\n",
    "        actor = row['Source']\n",
    "        if actor not in actor_nodes:\n",
    "            xml_actor_nodes += create_actor_node(actor)\n",
    "            actor_nodes.add(actor)\n",
    "\n",
    "        # Add data node if not already created\n",
    "        data_piece_name = row['Target']\n",
    "        if data_piece_name not in data_nodes:\n",
    "            xml_data_nodes += create_xml_node(row)\n",
    "            data_nodes.add(data_piece_name)\n",
    "\n",
    "        # Create edges for subsum relations (avoiding repetition)\n",
    "        subsum_edges = create_subsum_edges(row, created_subsum_edges)\n",
    "        for edge in subsum_edges:\n",
    "            xml_subsum_edges += edge\n",
    "\n",
    "        # Create collect edges (merging multiple texts for the same source-target pair)\n",
    "        create_collect_edges(row, collect_edges_tracker)\n",
    "\n",
    "    # Now, create the collect edges with combined texts\n",
    "    for (actor, data_piece_name), texts in collect_edges_tracker.items():\n",
    "        combined_text = \"\\n\".join(texts)  # Combine the texts into one string, with new lines\n",
    "        xml_collect_edges += f\"\"\"\n",
    "<edge source=\"{actor}\" target=\"{data_piece_name}\" id=\"edge_collect_{actor}_{data_piece_name}\">\n",
    "    <data key=\"d2\">COLLECT</data>\n",
    "    <data key=\"d3\">{combined_text}</data>\n",
    "</edge>\n",
    "\"\"\"\n",
    "\n",
    "    # Combine all nodes first and then edges in the correct order\n",
    "    final_xml_structure = f\"<graph>\\n{xml_actor_nodes}\\n{xml_data_nodes}\\n{xml_subsum_edges}\\n{xml_collect_edges}\\n</graph>\"\n",
    "    \n",
    "    # Write the XML structure to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(final_xml_structure)\n",
    "        \n",
    "    print(f\"XML written to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming df is your pandas DataFrame with the relevant columns\n",
    "output_file = 'output.xml'  # Specify the output file name\n",
    "generate_xml_from_dataframe(df, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3b6c6-c92e-49d6-8f27-1ee18751ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe81631-3948-49f7-8a4b-6d9f6813c573",
   "metadata": {},
   "source": [
    "### Generating the lists of unique actors and unique data pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def0dba1-14d1-4377-aeb3-217de1156212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Actors:\n",
      "We (TikTok)\n",
      "Advertising, Measurement and Other Partners\n",
      "Merchants, Payment and Transaction Fulfillment Providers\n",
      "Third Party Platforms\n",
      "Other Users\n",
      "Third Party Services with TikTok Developer Tools\n",
      "Third Party Providers\n",
      "Organisations, Businesses, People, and Others\n",
      "Service Providers\n",
      "Third Party Platforms and Partners\n",
      "Advertisers\n",
      "Third Party Measurement Providers\n",
      "Merchants, Payment and Transaction Fulfilment Providers, and Other Service Providers\n",
      "Entities within our corporate group\n",
      "Users and the Public\n",
      "Search Engines, Content Aggregators, and News Sites\n",
      "Researchers\n",
      "Corporate Transaction Parties\n",
      "Law Enforcement Agencies, or Other Third Parties\n",
      "Public Authorities\n",
      "Copyright Holders\n",
      "Other Third Parties\n",
      "\n",
      "Unique Data Pieces:\n",
      "Date of Birth\n",
      "Username\n",
      "Email Address\n",
      "Telephone Number\n",
      "Password\n",
      "Profile Bio\n",
      "Profile Photo\n",
      "Photographs\n",
      "Videos\n",
      "Audio Recordings\n",
      "Livestreams\n",
      "Comments\n",
      "Hashtags\n",
      "Feedback\n",
      "Reviews\n",
      "Creation Time\n",
      "Creation Date\n",
      "Location of Content Creation\n",
      "Creator Identity\n",
      "Clipboard Text\n",
      "Clipboard Images\n",
      "Clipboard Videos\n",
      "Location Information\n",
      "Message Content\n",
      "Timestamps\n",
      "Chats with Merchants\n",
      "Virtual Assistant Interactions\n",
      "Names from Phone Book\n",
      "Phone Numbers from Phone Book\n",
      "Email Addresses from Phone Book\n",
      "Your Social Network Public Profile Information\n",
      "Names of Social Network Contacts\n",
      "Profiles of Social Network Contacts\n",
      "Contacts Provided by Others\n",
      "Payment Card Information\n",
      "Billing Information\n",
      "Delivery Information\n",
      "Contact Information (Purchases)\n",
      "Items Purchased\n",
      "Survey Responses\n",
      "Research Participation Data\n",
      "Contest Entries\n",
      "Marketing Campaign Participation\n",
      "Event Participation\n",
      "Proof of Identity\n",
      "Proof of Age\n",
      "Feedback or Inquiries\n",
      "Information about Possible Violations\n",
      "Form Data\n",
      "Device Model\n",
      "Operating System\n",
      "Keystroke Patterns or Rhythms\n",
      "IP Address\n",
      "System Language\n",
      "Crash Reports\n",
      "Performance Logs\n",
      "Device ID\n",
      "User ID\n",
      "Approximate Location (SIM and IP)\n",
      "Approximate Location (Device)\n",
      "Content Viewed\n",
      "Duration of Use\n",
      "Frequency of Use\n",
      "Engagement with Other Users\n",
      "Search History\n",
      "Settings\n",
      "Objects and Scenery Recognition\n",
      "Face or Body Part Detection\n",
      "Speech-to-Text Transcriptions\n",
      "Inferred Age-Range\n",
      "Inferred Gender\n",
      "Interests and Preferences\n",
      "Cookie Identifiers\n",
      "Session Tokens\n",
      "Web Beacons\n",
      "Pixel Tags\n",
      "Activities on Other Websites and Apps\n",
      "Products or Services Purchased Elsewhere\n",
      "Mobile Identifiers for Advertising\n",
      "Hashed Email Addresses\n",
      "Hashed Phone Numbers\n",
      "Payment Confirmation Details\n",
      "Email Address from Third Parties\n",
      "User ID from Third Parties\n",
      "Public Profile from Third Parties\n",
      "Contact Information Synced by Others\n",
      "Data from TikTok Developer Tools Integrations\n",
      "Safety and Content Moderation Data\n",
      "Publicly Available Information\n",
      "Data from Government Authorities\n",
      "Data from Professional Organisations\n",
      "Data from Charity Groups\n",
      "Mentions in Content\n",
      "Content Metadata\n",
      "Cookie Identifiers (Third Parties)\n",
      "Delivery Information (from Merchants)\n",
      "Information about ad performance\n",
      "Payment Card Details\n",
      "Transaction Amounts\n",
      "Purchase or Payment Dates\n",
      "Shipping Address\n",
      "Delivery Status\n",
      "Network Type\n",
      "Merchant Communications\n",
      "Text from Clipboard\n",
      "Images from Clipboard\n",
      "Videos from Clipboard\n",
      "Creation Time and Date\n",
      "Duration and Frequency of Use\n",
      "Interactions with Other Users\n",
      "Search Queries\n",
      "Browsing History\n",
      "Language Preferences\n",
      "Notification Settings\n",
      "Ambiguous or Non-specified Data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './../draft_six_columns.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get unique actors from the 'Source' column\n",
    "unique_actors = df['Source'].unique().tolist()\n",
    "\n",
    "# Get unique data pieces from the 'Target' column\n",
    "unique_data_pieces = df['Target'].unique().tolist()\n",
    "\n",
    "# Print unique actors\n",
    "print(\"Unique Actors:\")\n",
    "for actor in unique_actors:\n",
    "    print(actor)\n",
    "\n",
    "# Print unique data pieces\n",
    "print(\"\\nUnique Data Pieces:\")\n",
    "for data_piece in unique_data_pieces:\n",
    "    print(data_piece)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346a76a-8f47-4cea-b7f0-36335da05c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d78b4-67be-4145-8503-c6225046909e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228d6e4-2823-415b-9b53-ea80c2a8ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
